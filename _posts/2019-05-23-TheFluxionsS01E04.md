---
layout: post
title: "S01E04 - DEMON-IA"
#color: black
author: thefluxions
feature-img: "assets/img/view/S01E04.jpg"
thumbnail: "assets/img/view/S01E04.jpg"
image: "assets/img/view/S01E04.jpg"
#excerpt_separator: <!--more-->
#tags: 
---


Hoy Newton escucharía debajo del árbol a Bart y Mike preguntándose si tenemos plena decisión sobre nuestras acciones diarias. Cada vez más algoritmos basados en la Inteligencia Artificial controlan nuestra vida. Aunque todavía no hemos visto a Terminator por las calles, estos algoritmos se usan cada vez más para tomar decisiones que inciden directamente en nuestras vidas: la conducción de vehículos, diagnósticos médicos, concesión de créditos… ¿Qué pasaría si estos algoritmos no fueran todo lo bien que deberían? ¿Y si toman decisiones arbitrarias? Si queréis saber un poco más sobre este tenebroso asunto o solo queréis echar un buen rato con vuestros podcasters favoritos: Play y fluxea.
<br>
<p align="center">
<a href="https://www.spreaker.com/user/radiolabugr/the-fluxions-1x04" target="_blank"><img src="https://raw.githubusercontent.com/thefluxions/thefluxions.github.io/master/assets/img/archive/spreaker-logo.png" height="100" align="center"></a>

<a href="https://open.spotify.com/episode/3xsbbRgi6ZdbTxN6CcOsjS?si=yppvQKMNRsCzL_hJRIWzVQ" target="_blank"><img src="https://raw.githubusercontent.com/thefluxions/thefluxions.github.io/master/assets/img/archive/spotify-logo.png" height="100" align="center"></a>

<a href="https://podcasts.apple.com/es/podcast/1x04-demon-ia/id1492409246?i=1000460270481" target="_blank"><img src="https://raw.githubusercontent.com/thefluxions/thefluxions.github.io/master/assets/img/archive/apple-logo.png" height="100" align="center"></a>
<br><br>
<a href="https://www.ivoox.com/1x04-demon-ia-audios-mp3_rf_47189369_1.html" target="_blank"><img src="https://raw.githubusercontent.com/thefluxions/thefluxions.github.io/master/assets/img/archive/ivoox-logo.png" height="100" align="center"></a>

<a href="" target="_blank"><img src="https://raw.githubusercontent.com/thefluxions/thefluxions.github.io/master/assets/img/archive/youtube-logo.png" height="100" align="center"></a>

<a href="https://medialab.ugr.es/evento/the-fluxions-1x04-demon-ia" target="_blank"><img src="https://raw.githubusercontent.com/thefluxions/thefluxions.github.io/master/assets/img/archive/medialab-logo.png" height="100" align="center"></a>
</p>
<br><br>

## Referencias

* [Fortman-Roe, S. (2012, junio). Understanding the Bias-Variance Tradeoff. Scott Fortmann-Roe.](http://scott.fortmann-roe.com/docs/BiasVariance.html)
* [Demming, A. (2019, 1 julio). Machine learning collaborations accelerate materials discovery –. Physics World.](https://physicsworld.com/a/machine-learning-collaborations-accelerate-materials-discovery/)
* [Study finds algorithm no better than random people at predicting recidivism. (2018, enero). Privacy International.](https://privacyinternational.org/examples-abuse/1962/study-finds-algorithm-no-better-random-people-predicting-recidivism)
* [ProPublica. (2020, 29 febrero). Machine Bias.](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
* [Simpson’s Paradox (Stanford Encyclopedia of Philosophy). (2021, 24 marzo). Stanford Encyclopedia of Philosophy.](https://plato.stanford.edu/entries/paradox-simpson/)
* [BBC News Mundo. (2015, 2 julio). Google pide perdón por confundir a una pareja negra con gorilas.](https://www.bbc.com/mundo/noticias/2015/07/150702_tecnologia_google_perdon_confundir_afroamericanos_gorilas_lv)
* [Dastin, J. (2018, 14 octubre). Amazon abandona un proyecto de IA para la contratación por su sesgo sexista. U.S.](https://www.reuters.com/article/amazon-com-contratacion-ia-idESKCN1MO0M4)

## Música

* Edición de audio y música montada y editada por RadioLab UGR.

## Galería

{% include aligner.html images="view/S01E04_1.jpg,view/S01E04_2.jpg,view/S01E04_3.jpg,view/S01E04_4.jpg" column=1 %}